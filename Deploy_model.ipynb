{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSBAyH9gIFqO",
    "outputId": "b8bf2be8-61b8-4406-ca6a-389abdbcb871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive',force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uN0uDn9TIAMh"
   },
   "outputs": [],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OiKbV6GqIIE5"
   },
   "outputs": [],
   "source": [
    "!pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HpFYz1IVIQEx"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-object-detection-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kV81BfRCIIoe",
    "outputId": "214fffa8-bf60-47e0-c4bd-ac62f57f1f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py \n",
    "\n",
    "#write script in app.py\n",
    "\n",
    "import streamlit as st\n",
    "import os\n",
    "import collections\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')           # Suppress TensorFlow logging (2)\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "import imutils\n",
    "from object_detection.utils import ops as utils_ops\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def resize_image(img_path):\n",
    "  img = Image.open(img_path) # image extension *.png,*.jpg\n",
    "  new_width  = 640\n",
    "  new_height = 640\n",
    "  img_resize = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
    "  return np.asarray(img_resize)\n",
    "  #img_resize.save('test_image.jpg')\n",
    "  #plt.figure(figsize=(5,5))\n",
    "  #plt.imshow(img_resize)\n",
    "\n",
    "\n",
    "\n",
    "def final_pipeline1(test_img_path,detect_fn):\n",
    "\n",
    "  utils_ops.tf = tf.compat.v1\n",
    "  tf.gfile = tf.io.gfile\n",
    "  PATH_TO_LABELS = '/content/drive/MyDrive/label_map.pbtxt'\n",
    "\n",
    "  category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                      use_display_name=True)\n",
    "\n",
    "\n",
    "  print('Running inference... ')\n",
    "\n",
    "  image_np = resize_image(test_img_path)\n",
    "  #print('\\nimage shape : ', image_np.shape)\n",
    "  # Things to try:\n",
    "  # Flip horizontally\n",
    "  # image_np = np.fliplr(image_np).copy()\n",
    "\n",
    "  # Convert image to grayscale\n",
    "  # image_np = np.tile(\n",
    "  #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "\n",
    "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "  input_tensor = tf.convert_to_tensor(image_np)\n",
    "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "  #print(input_tensor.shape)\n",
    "  input_tensor = input_tensor[tf.newaxis, ...]\n",
    "  #print(input_tensor.shape)\n",
    "  # input_tensor = np.expand_dims(image_np, 0)\n",
    "  detections = detect_fn(input_tensor)\n",
    "  #print(detections)\n",
    "  # All outputs are batches tensors.\n",
    "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "  # We're only interested in the first num_detections.\n",
    "  num_detections = int(detections.pop('num_detections'))\n",
    "  detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "  #print('detections : ',detections)\n",
    "  detections['num_detections'] = num_detections\n",
    "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "  #print(detections)\n",
    "\n",
    "  image_np_with_detections = image_np.copy()\n",
    "\n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'],\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=.29,\n",
    "        agnostic_mode=False)\n",
    "\n",
    "  #plt.figure(figsize=(10,10))\n",
    "  #plt.title('Detected Image : ')\n",
    "  #plt.imshow(image_np_with_detections)\n",
    "  st.text('Damage Detected Image : ')\n",
    "  st.image(image_np_with_detections,caption = 'Detected Image')\n",
    "  #print('Done')\n",
    "  #plt.show()\n",
    "@st.cache(allow_output_mutation = True)\n",
    "def load_model():\n",
    "  PATH_TO_MODEL_DIR = '/content/drive/MyDrive/object_detection/mobile_ner_v2_fpnlite_640x640/exporter2'\n",
    "\n",
    "  PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n",
    "  # Load saved model and build the detection function\n",
    "  detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
    "  return detect_fn\n",
    "\n",
    "st.set_option('deprecation.showfileUploaderEncoding',False)\n",
    "st.title('Road Damage Detection App')\n",
    "st.text('Build With Streamlit')\n",
    "\n",
    "with st.spinner('Loading model ......'):\n",
    "  detect_fn = load_model()\n",
    "\n",
    "#upload image:\n",
    "image_file = st.file_uploader('Upload Image',type=['jpg','png','jpeg'])\n",
    "#inference:\n",
    "if image_file is not None:\n",
    "    our_image = Image.open(image_file)\n",
    "    st.text('Original Image :')\n",
    "    st.image(our_image)\n",
    "    test_img_path =image_file\n",
    "    with st.spinner('Detecting Road Damage ......'):\n",
    "      final_pipeline1(test_img_path,detect_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iAtr57MIifj",
    "outputId": "81060d10-c858-4c24-b2bb-cad261b2bc9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n",
      "NgrokTunnel: \"http://f6d3ac4e0229.ngrok.io\" -> \"http://localhost:80\"\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken XXXXXXXXXXXXXXXXXXX\n",
    "#authentication key will after login ngrok\n",
    "\n",
    "from pyngrok import ngrok\n",
    "#connecting to port = 80\n",
    "public_url = ngrok.connect(port=80)\n",
    "print (public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYshbSN1Ix4W",
    "outputId": "decf0b04-b7eb-4c80-af1f-f4c96b79887e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:80\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.125.129.78:80\u001b[0m\n",
      "\u001b[0m\n",
      "2020-12-12 13:28:20.843418: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Running inference... \n",
      "\u001b[34m  Stopping...\u001b[0m\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!export STREAMLIT_SERVER_PORT=80\n",
    "#running Script using streamlit:\n",
    "!streamlit run app.py --server.port 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEZtiscRIyoR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deploy_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
